{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd641ae-0f5a-4148-8aba-bfdac2b0ee69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "data = [(\"id1\", \"Product A!@#\"), (\"id2\", \"Item B$%^\"), (\"id3\", \"Value C&*-\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"product_name\"])\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f9c13d9-3b9d-4d4a-830d-9d480397cd1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Replace special characters in 'product_name' column with an empty string\n",
    "df_cleaned = df.withColumn(\"product_name_cleaned\", regexp_replace(\"product_name\", \"[^a-zA-Z]\", \"\"))\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c5f20f0-68a8-4579-8316-f68d7d31776a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(1, 100), (2,200), (3,300),(4,400),(5,500)]\n",
    "df = spark.createDataFrame(data, [\"id\", \"salary\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b48fc4-6b0e-402a-b59e-31d353ac4109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from {df} order by salary desc limit 1 offset 0\",df=df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c051bd2-a34b-43c7-9bf2-1354649b4f66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(1,\"ravi\",2), (2, \"kavi\",3), (3, \"hari\",4),(4, \"giri\",2),(5, \"siri\",3),(6, \"pari\",2)]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\",\"mgr\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cac9577-b0da-41be-9771-5db873280fbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"emp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "711ecaae-25f2-46c0-8761-8ae4bc1a0140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select e.id, e.name, e.mgr, mgr.id, mgr.name, mgr.mgr , srmgr.id ,srmgr.name\n",
    "from emp e \n",
    "left join emp mgr on e.mgr = mgr.id\n",
    "left join emp srmgr on  mgr.mgr = srmgr.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59bb2ab5-7076-4ed8-9689-1f77e59d81fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "\n",
    "select e2.id,e2.name from emp e1 \n",
    "join emp e2 on e1.mgr = e2.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "222b993d-b1d6-4c9f-9c7b-8a1eece1427b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with cte as(\n",
    "select mgr, count(1) as cnt from emp group by mgr\n",
    ")\n",
    "select e.name, cnt from cte \n",
    "join emp e on cte.mgr = e.id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "488ace00-5ebe-4a9a-8861-1b28290dfa95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(1,2), (2, 3), (3,4),(3,2),(2,1),(4,1)]\n",
    "pdf = spark.createDataFrame(data, [\"p1\", \"p2\"])\n",
    "pdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0c78e77-11a5-402e-b165-f017936b21a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caf7342d-6403-40f5-a6bd-47e2b297be08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "\n",
    "select least(p1,p2) as frm, greatest(p1,p2) as gtr, count(1) from person group by 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33fad13a-2ab4-4318-b70d-90a300c9f4d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Counting elements in a list\n",
    "data = ['apple', 'banana', 'apple', 'orange', 'banana', 'apple']\n",
    "counts = Counter(data)\n",
    "print(f\"Counts from list: {counts}\")\n",
    "\n",
    "x = [k for k, v in counts.items() if v> 1]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbf267bd-05dd-4b28-8a84-bb0e001265f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = [(\"id1\", \"Product A!@#\"), (\"id2\", \"Item B$%^\"), (\"id3\", \"Value C&*-\"), (\"id3\", \"clean\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"product_name\"])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fb16849-3799-46d6-bd99-dca279c266eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "special_char_pattern = r\"[!@#$%^&*-]\"\n",
    "#df.withColumn('new', length(df.product_name))\n",
    "df.filter( (col('product_name').rlike(special_char_pattern)) | (length(df.product_name)> lit(5))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f435b8-bb6d-4acc-a644-870dbdea3c92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "balance_df = spark.createDataFrame(pd.DataFrame({\n",
    "    'CustId': ['C1', 'C2', 'C3', 'C4'],\n",
    "    'PolicyId': ['P1', 'P2', 'P3', 'P4'],\n",
    "    'ClaimId': [None, None, None, None],\n",
    "    'BalancePolicyAmount': [5000000, 500000, 5000000, 5000000],\n",
    "    'Date': ['10/10/2020', '10/10/2020', '10/10/2020', '10/10/2020']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddff1d33-a941-4650-9b08-bd2b4099e7fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "policy_df = spark.createDataFrame(pd.DataFrame({\n",
    "    'PolicyId': ['P1', 'P2', 'P3', 'P4', 'P5'],\n",
    "    'ActiveDate': ['10/10/2020', '10/10/2020', '12/10/2020', '13/10/2020', '14/10/2020'],\n",
    "    'ActiveStatus': ['Y', 'Y', 'N', 'Y', 'Y'],\n",
    "    'PolicyAmount': [5000000, 500000, 5000000, 5000000, 5000000]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78ff226f-eaa9-4584-80d7-e0d665b37cb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "claims_df = spark.createDataFrame(pd.DataFrame({\n",
    "    'ClaimId': ['Claim1', 'Claim1'],\n",
    "    'ClaimDate': ['11/10/2021', '11/10/2021'],\n",
    "    'ClaimAmount': [100000, 200000],\n",
    "    'ClaimAgainstPolicy': ['P1', 'P3']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903ca68a-fad8-4bae-b0e2-a36ad0048881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "policy_df.show()\n",
    "balance_df.show()\n",
    "claims_df.show()\n",
    "\n",
    "policy_df.createOrReplaceTempView(\"policy\")\n",
    "balance_df.createOrReplaceTempView(\"balance\")\n",
    "claims_df.createOrReplaceTempView(\"claims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6964be-f9af-42f5-a30e-36ca306d2d1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with balance as (\n",
    "select b.PolicyId, (b.balancePolicyAmount-c.ClaimAmount) as current_balance \n",
    "from balance b \n",
    "join claims c \n",
    "on c.claimAgainstPolicy = b.PolicyId \n",
    ")\n",
    "merge into erm.balance \n",
    "using balance b \n",
    "on b.PolicyId = balance.PolicyId\n",
    "when matched then update set b.BalancePolicyAmount = b.current_balance"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5514530485382392,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-08-04 14:08:26",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
